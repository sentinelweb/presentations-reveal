<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>Client side tensorflow </title>

	<link rel="stylesheet" href="css/reveal.css">
	<link rel="stylesheet" href="css/theme/league.css">

	<!-- Theme used for syntax highlighting of code -->
	<link rel="stylesheet" href="lib/css/zenburn.css">
	<link rel="stylesheet" href="tensorflow_client.css">

	<!-- Printing and PDF exports -->
	<script>
		var link = document.createElement('link');
		link.rel = 'stylesheet';
		link.type = 'text/css';
		link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
		document.getElementsByTagName('head')[0].appendChild(link);
	</script>
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<!-- make QR code : https://sentinelweb.github.io/reveal.js/beyond_mvp.html -->
			<!-- page 1 -->
			<section>
				<h1>Client side tensorflow</h1>
				<img src="tensorflow_client_images/tensorflow.png" />
			</section>
			<!-- page 2 -->
			<section>
				<h2>What we will cover ...</h2>
				<ul>
					<li class="fragment fade-up">Jargon buster</li>
					<li class="fragment fade-up">20,000 mile high overview of Tensorflow ecosystem</li>
					<li class="fragment fade-up">Training a model using TFPoets codelab scripts</li>
					<li class="fragment fade-up">Deployment on Android &amp; iOS using TFLite</li>
					<li class="fragment fade-up">Tensorflow.js</li>
					<li class="fragment fade-up">Pros &amp; cons of Client side</li>
					<li class="fragment fade-up">Possible usages &amp; TOIL reduction</li>
					<li class="fragment fade-up">Learning</li>
				</ul>
			</section>
			<section>
				<h2>Jargon buster</h2>
			</section>
			<section>
				<h2>Neural network</h2>
				<ul>
					<li>Transforms a set of inputs (features) into outputs (classifications)</li>
					<li class="fragment fade-up">Use a dataset to train - then measure classification accuracy (RMS)
						<aside class="notes">
							Consists of N-layers which can be a weight, and an activation function (switch).
							<br/> During training the error is propagated backwards to refine weights
						</aside>
					</li>
					<li class="fragment fade-up">Produces a
						<i>Model</i> which can used to classify input features</li>
				</ul>
			</section>
			<section>
				<h2>Transfer learning</h2>
				<ul>
					<li>Using pre-trained neural net which can be refined by just re-training the final layers</li>
					<li class="fragment fade-up">Requires less computation and less data to train</li>
				</ul>
			</section>
			<section>
				<h2>MobileNet</h2>
				<ul>
					<li>A set of image recognition models produced by google</li>
					<li class="fragment fade-up">Optimised for efficiency on mobile</li>
					<li class="fragment fade-up">Can be retrained for a specific purpose using transfer learning</li>
				</ul>
			</section>
			<section>
				<h2>Tensorflow Ecosystem</h2>
			</section>
			<section>
				<h2>Tensorflow API</h2>
				<ul>
					<li>A dataflow API for numerical computation that builds a graph</li>
					<li class="fragment fade-up">Graph gets built then executed on hardware - CPU, GPU, TPU</li>
				</ul>
			</section>
			<section>
				<h2>Tensorflow Languages</h2>
				<ul>
					<li class="fragment fade-up">Python : most advanced</li>
					<li class="fragment fade-up">Java (Kotlin)</li>
					<li class="fragment fade-up">JavaScript (New) - Tensorflow.js</li>
					<li class="fragment fade-up">Swift (Early stage)</li>
					<li class="fragment fade-up">Go</li>
					<li class="fragment fade-up">C / C++</li>
				</ul>
			</section>
			<section>
				<h2>Tensorflow API - Basics</h2>
				<ul>
					<li>The graph is is executed in a
						<code>tf.Session()</code>
					</li>
					<li class="fragment fade-up">Each tensorflow command has input and output data</li>
					<li class="fragment fade-up">The session holds the state</li>
					<li class="fragment fade-up">The graph execution can be parallelized where possible</li>
				</ul>
			</section>
			<section>
				<h2>Tensorflow sub-projects</h2>
				<ul>
					<li class="fragment fade-up">
						<span class="leader">Tensorflow.js</span> : Javascript bindng for tensorflow</li>
					<li class="fragment fade-up">
						<span class="leader">Tensorflow Lite</span> : Optimised &amp; efficient runtime for embedded / mobile devices</li>
					<li class="fragment fade-up">
						<span class="leader">Tensorflow Mobile</span> : TFLite's predecessor - less optimised but has more TF operations</li>
					<li class="fragment fade-up">
						<span class="leader">Hub</span> : Collaboration library to share tensorflow modules &amp; components</li>
					<li class="fragment fade-up">
						<span class="leader">TFX</span> : Production utilites and optimisation</li>
					<li class="fragment fade-up">
						<span class="leader">Magenta</span> : Art and music experimentation projects</li>
				</ul>
			</section>
			<section>
				<h2>Training a model using TFPoets</h2>
			</section>
			<section>
				<h2>Retraining - overview</h2>
				<ul>
					<li class="fragment fade-up">Use MobileNet model as a base to perform transfer learning on a set of images</li>
					<li class="fragment fade-up">Use Tensorboard webapp to monitor progress and debug graph</li>
					<li class="fragment fade-up">Produces a model which can be used for classification</li>
				</ul>
				<aside class="notes">
					Mention That we will build a "TrainSpotter" app
				</aside>
			</section>
			<section>
				<h2>Retraining - Dataset</h2>
				<ul>
					<li class="fragment fade-up">Collect lots of images (best == 1000s) into a directory</li>
					<li class="fragment fade-up">Example collected around 100 images from google of Trains</li>
					<li class="fragment fade-up">Labels : TGV, uk commuter, steam, freight, thomas the tank engine</li>
				</ul>
			</section>
			<section>
				<h2>Retraining - Run</h2>
				<ul>
					<li class="fragment fade-up">Execute retrain script in tensorflow for poets</li>
					<li class="fragment fade-up">More steps give a better model (takes longer) 500 &lt; steps &lt; 5000+</li>
					<li class="fragment fade-up">Monitor progress with tensorboard</li>
				</ul>
			</section>
			<section>
				<h3>Tensorboard - initial</h3>
				<img src="tensorflow_client_images/tensorboard_accuracy_1.png" />
			</section>
			<section>
				<h3>Tensorboard - in progress</h3>
				<img src="tensorflow_client_images/tensorboard_accuracy_2.png" />
			</section>
			<section>
				<h3>Tensorboard - final</h3>
				<img src="tensorflow_client_images/tensorboard_accuracy_3.png" />
			</section>
			<section>
				<h3>Tensorboard - graph</h3>
				<img src="tensorflow_client_images/tensorboard_graph_1.png" />
			</section>
			<section>
				<h3>Tensorboard - drill down</h3>
				<img src="tensorflow_client_images/tensorboard_graph_2.png" />
			</section>
			<section>
				<h2>Deploying on mobile</h2>
			</section>
			<section>
				<h2>Tensorflow Lite (TFLite)</h2>
				<ul>
					<li class="fragment fade-up">Optimised runtime for tensorflow models (Mobile/embedded)</li>
					<li class="fragment fade-up">Model is converted to .lite format using a tool called
						<code>toco</code>
					</li class="fragment fade-up">
					<li class="fragment fade-up">Lite format uses FlatBuffers - memory mapped for efficiency</li>
					<li class="fragment fade-up">Only supports a subset of Tensorflow operations (No transfer learning) &#x1F614;</li>
				</ul>
				<aside class="notes">
					<ul>
						<li>Memory mapping is more efficient as bytes can be loaded in memory directly without conversion</li>
					</ul>
				</aside>
			</section>
			<section>
				<h2>TFLite - Integration Android</h2>
				<pre><code>
Interpreter tflite = new Interpreter(loadModelFile());
List&lt;String&gt; labelList = loadLabelList(activity);
ByteBuffer imgData =
        ByteBuffer.allocateDirect(
            4 * IMG_SIZE_X * IMG_SIZE_Y * DIM_PIXEL_SIZE);
imgData.order(ByteOrder.nativeOrder());
labelProbArray = new float[1][labelList.size()];

// on image received
convertBitmapToByteBuffer(bitmap);
tflite.run(imgData, labelProbArray); 
					</code></pre>
				<aside class="notes">
					<ul>
						<li>Load model &amp; Create an interpreter </li>
						<li>Load the list of labels</li>
						<li>Allocate Bytebuffer to send data to interpreter</li>
						<li>When image is captured - convert bytes to native format and pass to TFLite</li>
						<li>Label probability array has the probabilty of each label</li>
					</ul>
				</aside>
			</section>
			<section style="max-width:100%;width:1000px">
				<h2>TFLite - Integration iOS</h2>
				<pre style="height:800px;width:1000px;"><code style="max-height:800px;width:1000px">
std::vector&lt;std::string&gt; labels;
std::unique_ptr&lt;tflite::FlatBufferModel&gt; model;
tflite::ops::builtin::BuiltinOpResolver resolver;
std::unique_ptr&lt;tflite::Interpreter&gt; interpreter;

// loading model and configure tflite instance
NSString* graph_path = FilePathForResourceName(model_file_name, model_file_type);
model = tflite::FlatBufferModel::BuildFromFile([graph_path UTF8String]);
LoadLabels(labels_file_name, labels_file_type, &amp;labels);
tflite::ops::builtin::BuiltinOpResolver resolver;
tflite::InterpreterBuilder(*model, resolver)(&amp;interpreter);

// on image received
[self inputImageToModel:image]; 
interpreter-&gt;Invoke() 
float* probs = interpreter-&gt;typed_output_tensor&lt;float&gt;(0);
					</code></pre>
				<aside class="notes">
					<ul>
						<li>Apologise for Objective C - no swift example</li>
						<li>Load model to
							<code>FlatBufferModel</code>
						</li>
						<li>Load the list of labels</li>
						<li>Initialise TFLite interpreter with model</li>
						<li>When image is captured - convert bytes to native format</li>
						<li>Invoke TFLite interpreter</li>
						<li>Get probabilities by calling interpreter-&gt;typed_output_tensor</li>
					</ul>
				</aside>
			</section>
			<section>
				<h2>Results - Trainspotter app</h2>
			</section>
			<section>
				<h3>Trainspotter - TGV</h3>
				<img src="tensorflow_client_images/app_1.png" />
			</section>
			<section>
				<h3>Trainspotter - Thomas</h3>
				<img src="tensorflow_client_images/app_2.png" />
			</section>
			<section>
				<h3>Trainspotter - Hugh</h3>
				<img src="tensorflow_client_images/app_3.png" />
			</section>
			<section>
				<h2>Tensorflow.js</h2>
				<ul>
					<li class="fragment fade-up">Javascript binding for the Tensorflow C library</li>
					<li class="fragment fade-up">Works in browser &amp; NodeJS</li>
					<li class="fragment fade-up">Can do transfer learning / retraining</li>
					<li class="fragment fade-up">Can use WebGL (Linux only ATM) (Faster)</li>
					<li class="fragment fade-up">Can use browser sensor data directly to retrain models</li>
					<li class="fragment fade-up">Not as fast as native implementations - gets slower with larger models</li>
					<li class="fragment fade-up">Exporting models in development progress &#x1F614;</li>
				</ul>
				<aside class="notes">
					<ul>
						<li>Performace measurements says around 1.5x slower than Python</li>
						<li>Can do ML using JavaScript !! - much lower barrier to entry</li>
					</ul>
				</aside>
			</section>
			<section>
				<h2>Tensorflow.js - installation &amp; running</h2>
				<ul>
					<li class="fragment fade-up">
						<code>yarn add @tensorflow/tfjs</code>
					</li>
					<li class="fragment fade-up">
						<code>node getting-started.js</code> &lt;-- whatever file
					</li>
				</ul>
			</section>
			<section>
				<h2>Client side ML - Advantages &#x1F60E;</h2>
				<ul>
					<li class="fragment fade-up">&quot;Free&quot; compute power (for running NN and feature processing)</li>
					<li class="fragment fade-up">Free real-time high definition data</li>
					<li class="fragment fade-up">Low latency</li>
					<li class="fragment fade-up">Access to onboard devices and hardware (camera, sensors, mic)</li>
					<li class="fragment fade-up">Customer data security - data doesn't leave device</li>
					<li class="fragment fade-up">for TF.js can use device input for retraining</li>
				</ul>
			</section>
			<section>
				<h2>Client side ML - Disdvantages &#x1F62C;</h2>
				<ul>
					<li class="fragment fade-up">Power usage can be high</li>
					<li class="fragment fade-up">Need to lots of model &amp; feature optimisation &#x1F613;</li>
				</ul>
			</section>
			<section>
				<h2>Usages/ideas .. toil reduction</h2>
				<ul>
					<li class="fragment fade-up">Image recognition - read tickets &amp; timetable boards (crowdsource real-time data)</li>
					<li class="fragment fade-up">Help assistant - Natural Language Processing</li>
					<li class="fragment fade-up">UI customisation for the user</li>
					<li class="fragment fade-up">Selleing extra products based on customer's present situation</li>
					<li class="fragment fade-up">ML becomes more useful as software complexity grows
						<aside class="notes">If all states can be computed and labelled you can train a small NN that can replace complex if/switch case</aside>
					</li>
				</ul>
			</section>
			<section>
				<h2>Learning utilities</h2>
				<ol>
					<li class="fragment fade-up">TensorFlow for poets codelabs : Beginner
						<br/>
						<a href="https://codelabs.developers.google.com/?cat=TensorFlow">https://codelabs.developers.google.com/?cat=TensorFlow</a>
					</li>
					<li class="fragment fade-up">Machine learning crash course : Nice ML intro
						<br/>
						<a href="https://developers.google.com/machine-learning/crash-course/">https://developers.google.com/machine-learning/crash-course/</a>
					</li>
					<li class="fragment fade-up">TensorFlow tutorials : Deep dive into areas
						<br/>
						<a href="https://www.tensorflow.org/tutorials/">https://www.tensorflow.org/tutorials/</a>
					</li>
					<li class="fragment fade-up">GDG cloud group - Monday meetups</li>
				</ol>
			</section>
			<section>
				<h2>Thanks &#x1F603;</h2>
				<ul>
					<li>Rob Munro</li>
					<li>#tltechsummit18</li>
					<li>Robs TF learning repo:
						<br/>
						<a href="https://github.com/sentinelweb/tensorflow_learn">https://github.com/sentinelweb/tensorflow_learn</a>
					</li>
				</ul>
			</section>
		</div>
	</div>

	<script src="lib/js/head.min.js"></script>
	<script src="js/reveal.js"></script>

	<script>
		// More info about config & dependencies:
		// - https://github.com/hakimel/reveal.js#configuration
		// - https://github.com/hakimel/reveal.js#dependencies
		Reveal.initialize({
			dependencies: [
				{ src: 'plugin/markdown/marked.js' },
				{ src: 'plugin/markdown/markdown.js' },
				{ src: 'plugin/notes/notes.js', async: true },
				{ src: 'plugin/highlight/highlight.js', async: true, callback: function () { hljs.initHighlightingOnLoad(); } }
			],
			history: true,
			slideNumber: 'c/v/t'
		});
	</script>
</body>

</html>